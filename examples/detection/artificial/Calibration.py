# Copyright (C) 2019-2020 Ruhr West University of Applied Sciences, Bottrop, Germany
# AND Visteon Electronics Germany GmbH, Kerpen, Germany
#
# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.

"""
Use this file to calibrate the confidence of the artificial dataset to demonstrate the effect of position-dependent
confidence calibration used for object detection calibration.
"""

import numpy as np
from typing import Union
from netcal.binning import HistogramBinning
from netcal.scaling import BetaCalibration, BetaCalibrationDependent, LogisticCalibration, LogisticCalibrationDependent
from sklearn.model_selection import train_test_split
import os


def calibration(samples: dict, bins: Union[tuple, list], save_models: bool = False, random_state: int = None) -> dict:
    """
    Do example calibration on the artificial dataset created by the module "CreateDataset".

    Parameters
    ----------
    samples : dict
        Dictionary with samples generated by module "CreateDataset".
    bins : iterable
        Number of bins in each direction.
    save_models : bool, optional, default: False
        If True, save all models on disk.
    random_state : int, optional, default: None
        Random state as seed for train/test split

    Returns
    -------
    dict
        Dictionary with splitted test data and calibrated confidence estimates.
    """

    # extract values from dict
    matched = samples['matched']
    confidences = samples['confidences']
    cx = samples['cx']
    cy = samples['cy']

    # check if save directory exists if models should be stored on disk
    if save_models:
        if not os.path.isdir("models"):
            os.makedirs("models", exist_ok=True)

    # stratified random split
    conf_train, conf_test, cx_train, cx_test, cy_train, cy_test, matched_train, matched_test = \
        train_test_split(confidences, cx, cy, matched,
                         train_size=0.7,
                         shuffle=True,
                         stratify=matched,
                         random_state=random_state)

    # calibration results are stored in this dict
    results = {'confidence': conf_test, 'matched': matched_test, 'cx': cx_test, 'cy': cy_test}

    # -----------------------------------------
    # 0D methods with confidence only
    hist = HistogramBinning(bins=bins[0], detection=True)
    betacal = BetaCalibration(detection=True)
    lr_calibration = LogisticCalibration(temperature_only=False, detection=True)

    methods0d = [("hist", hist), ("betacal", betacal), ("lr_calibration", lr_calibration)]

    # iterate over 0D models, build calibration mapping and perform calibration
    for name, method in methods0d:

        method.fit(conf_train, matched_train)
        results[name] = method.transform(conf_test)

        if save_models:
            method.save_model("models/%s.pkl" % name)

    # -----------------------------------------
    # 2D methods with confidence and x/y position

    hist2d = HistogramBinning(bins=bins, detection=True)
    betacal2d = BetaCalibration(detection=True)
    betacal_dependent2d = BetaCalibrationDependent(momentum=True, detection=True)
    lr_calibration2d = LogisticCalibration(temperature_only=False, detection=True)
    lr_calibration_dependent2d = LogisticCalibrationDependent(detection=True)

    methods2d = [("hist2d", hist2d), ("betacal2d", betacal2d), ("betacal_dependent2d", betacal_dependent2d),
                 ("lr_calibration2d", lr_calibration2d), ("lr_calibration_dependent2d", lr_calibration_dependent2d)]

    # iterate over 2D models, build calibration mapping and perform calibration
    conf_train_2d = np.stack((conf_train, cx_train, cy_train), axis=1)
    conf_test_2d = np.stack((conf_test, cx_test, cy_test), axis=1)

    # iterate over 0D models, build calibration mapping and perform calibration
    for name, method in methods2d:

        method.fit(conf_train_2d, matched_train)
        results[name] = method.transform(conf_test_2d)

        if save_models:
            method.save_model("models/%s.pkl" % name)

    return results


if __name__ == '__main__':

    bins = [15, 15, 15]
    save_models = True
    random_state = None

    # read generated artificial data
    with open('artificial_dataset.npz', 'rb') as open_file:
        npz = np.load(open_file)
        samples = dict(npz)

    results = calibration(samples, bins, save_models, random_state)

    # save calibrated confidences as numpy array
    with open("calibrated_dataset.npz", "wb") as open_file:
        np.savez_compressed(open_file, **results)
