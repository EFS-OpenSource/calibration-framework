<!DOCTYPE html>




<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>netcal.regression.gp.GPNormal &mdash; net:cal API Reference</title>
    <meta name="description" content="">
    <meta name="author" content="">

    

<link rel="stylesheet" href="../../../_static/css/basicstrap-base.css" type="text/css" />
<link rel="stylesheet" id="current-theme" href="../../../_static/css/bootstrap3/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" id="current-adjust-theme" type="text/css" />

<link rel="stylesheet" href="../../../_static/css/font-awesome.min.css">

<style type="text/css">
  body {
    padding-top: 60px;
    padding-bottom: 40px;
  }
</style>

<link rel="stylesheet" href="../../../_static/css/basicstrap.css" type="text/css" />
<link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
<link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
<link rel="stylesheet" href="../../../_static/css/basicstrap.css" type="text/css" />
    
<script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
            URL_ROOT:    '../../../',
            VERSION:     '1.3.4',
            COLLAPSE_INDEX: false,
            FILE_SUFFIX: '.html',
            HAS_SOURCE:  true
  };
</script>
    <script type="text/javascript" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/sphinx_highlight.js"></script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/javascript" src="../../../_static/js/bootstrap3.min.js"></script>
<script type="text/javascript" src="../../../_static/js/jquery.cookie.min.js"></script>
<script type="text/javascript" src="../../../_static/js/basicstrap.js"></script>
<script type="text/javascript">
</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="top" title="net:cal API Reference" href="../../../index.html" />
    <link rel="up" title="netcal.regression.gp" href="../netcal.regression.gp.html" />
    <link rel="next" title="netcal.regression.gp.GPCauchy" href="netcal.regression.gp.GPCauchy.html" />
    <link rel="prev" title="netcal.regression.gp.GPBeta" href="netcal.regression.gp.GPBeta.html" /> 
  </head>
  <body role="document">
    <div id="navbar-top" class="navbar navbar-fixed-top navbar-default" role="navigation" aria-label="top navigation">
      <div class="container-fluid">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../../../index.html">net:cal API Reference</a>
        </div>
        <div class="navbar-collapse collapse">
          <ul class="nav navbar-nav navbar-right">
              <li class="dropdown visible-xs">
                <a role="button" id="localToc" data-toggle="dropdown" data-target="#" href="#">Table Of Contents <b class="caret"></b></a>
                <ul class="dropdown-menu localtoc sp-localtoc" role="menu" aria-labelledby="localToc">
                <ul>
<li><a class="reference internal" href="#">netcal.regression.gp.GPNormal</a><ul>
<li><a class="reference internal" href="#netcal.regression.gp.GPNormal"><code class="docutils literal notranslate"><span class="pre">GPNormal</span></code></a></li>
</ul>
</li>
</ul>

                </ul>
              </li>

            
              <li><a href="netcal.regression.gp.GPBeta.html" title="netcal.regression.gp.GPBeta" accesskey="P">previous </a></li>
              <li><a href="netcal.regression.gp.GPCauchy.html" title="netcal.regression.gp.GPCauchy" accesskey="N">next </a></li>
              <li><a href="../../../py-modindex.html" title="Python Module Index" >modules </a></li>
              <li><a href="../../../genindex.html" title="General Index" accesskey="I">index </a></li>
              <li><a href="../../netcal.regression.html" >netcal.regression</a></li>
              <li><a href="../netcal.regression.gp.html" accesskey="U">netcal.regression.gp</a></li>
            
            <li class="visible-xs"><a href="../../../_sources/_autosummary/_autosummary_regression_gp/_autosummary_regression_gp/netcal.regression.gp.GPNormal.rst.txt" rel="nofollow">Show Source</a></li>

            <li class="visible-xs">
                <form class="search form-search form-inline navbar-form navbar-right sp-searchbox" action="../../../search.html" method="get">
                  <div class="input-append input-group">
                    <input type="text" class="search-query form-control" name="q" placeholder="Search...">
                    <span class="input-group-btn">
                    <input type="submit" class="btn" value="Go" />
                    </span>
                  </div>
                  <input type="hidden" name="check_keywords" value="yes" />
                  <input type="hidden" name="area" value="default" />
                </form>
            </li>

            

          </ul>

        </div>
      </div>
    </div>
    

    <!-- container -->
    <div class="container-fluid">

      <!-- row -->
      <div class="row">
         
<div class="col-md-3 hidden-xs" id="sidebar-wrapper">
  <div class="sidebar hidden-xs" role="navigation" aria-label="main navigation">
<h3><a href="../../../index.html">Table of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../netcal.binning.html">netcal.binning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../netcal.scaling.html">netcal.scaling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../netcal.regularization.html">netcal.regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../netcal.metrics.html">netcal.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../netcal.presentation.html">netcal.presentation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../netcal.regression.html">netcal.regression</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../netcal.regression.html#probabilistic-regression-calibration-package">Probabilistic Regression Calibration Package</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../netcal.regression.html#available-classes">Available classes</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../netcal.regression.html#package-for-gaussian-process-optimization">Package for Gaussian process optimization</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../netcal.regression.gp.html">netcal.regression.gp</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../netcal.regression.gp.html#regression-gp-calibration-package">Regression GP Calibration Package</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../netcal.regression.gp.html#available-classes">Available classes</a><ul class="current">
<li class="toctree-l5"><a class="reference internal" href="netcal.regression.gp.AbstractGP.html">netcal.regression.gp.AbstractGP</a></li>
<li class="toctree-l5"><a class="reference internal" href="netcal.regression.gp.GPBeta.html">netcal.regression.gp.GPBeta</a></li>
<li class="toctree-l5 current"><a class="current reference internal" href="#">netcal.regression.gp.GPNormal</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#netcal.regression.gp.GPNormal"><code class="docutils literal notranslate"><span class="pre">GPNormal</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="netcal.regression.gp.GPCauchy.html">netcal.regression.gp.GPCauchy</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../netcal.regression.gp.html#packages">Packages</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../_autosummary_abstract_calibration/netcal.AbstractCalibration.html">netcal.AbstractCalibration</a></li>
</ul>

<div id="searchbox" role="search">
  <h3>Quick search</h3>
  <form class="search form-inline" action="../../../search.html" method="get">
      <div class="input-append input-group">
        <input type="text" class="search-query form-control" name="q" placeholder="Search...">
        <span class="input-group-btn">
        <input type="submit" class="btn" value="Go" />
        </span>
      </div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
  </div>
</div> 
        

        <div class="col-md-9" id="content-wrapper">
          <div class="document" role="main">
            <div class="documentwrapper">
              <div class="bodywrapper">
                <div class="body">
                  
  <section id="netcal-regression-gp-gpnormal">
<h1>netcal.regression.gp.GPNormal<a class="headerlink" href="#netcal-regression-gp-gpnormal" title="Permalink to this heading">Â¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="netcal.regression.gp.GPNormal">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">netcal.regression.gp.</span></span><span class="sig-name descname"><span class="pre">GPNormal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_inducing_points</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_random_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">correlations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gpnormal'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#netcal.regression.gp.GPNormal" title="Permalink to this definition">Â¶</a></dt>
<dd><p>GP-Normal recalibration method for regression uncertainty calibration using a temperature scaling for the
variance of a normal distribution but using the Gaussian process (GP) parameter estimation to adaptively
obtain the scaling parameter for each input individually.
The temperature scaling for the variance <a class="footnote-reference brackets" href="#id7" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>, <a class="footnote-reference brackets" href="#id8" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a> seeks to preserve a parametric Gaussian distribution as
calibration output and aims to reach <em>variance calibration</em>. That is, matching the predicted variance with the
observed âerror varianceâ aka mean squared error.
In contrast to the standard approach, the GP-Normal <a class="footnote-reference brackets" href="#id9" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> uses a Gaussian process (GP) from <a class="footnote-reference brackets" href="#id10" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a> to flexibly obtain
a recalibration weight for each sample individually.
Thus, the GP-Normal seeks for a mixed form of <strong>variance calibration</strong> in a more flexible way towards
<strong>distribution calibration</strong> for Gaussians.
Note that this method does not change the mean but only the predicted variance.</p>
<p><strong>Mathematical background:</strong> Let <span class="math notranslate nohighlight">\(f_Y(y)\)</span> denote the uncalibrated probability density function (PDF),
targeting the probability distribution for <span class="math notranslate nohighlight">\(Y\)</span>. In our case, the PDF is given as a Gaussian, so that
<span class="math notranslate nohighlight">\(f_Y(y) = \mathcal{N}\big(y; \mu_Y(X), \sigma^2_Y(X)\big)\)</span> with mean <span class="math notranslate nohighlight">\(\mu_Y(X)\)</span> and variance
<span class="math notranslate nohighlight">\(\sigma^2_Y(X)\)</span> obtained by a probabilistic regression model that depends on the input <span class="math notranslate nohighlight">\(X\)</span>.
The calibrated PDF <span class="math notranslate nohighlight">\(g_Y(y)\)</span> is the rescaled Gaussian with fixed mean and rescaled variance, so that</p>
<div class="math notranslate nohighlight">
\[g_Y(y) = \mathcal{N}\Big(y; \mu_Y(X), \big(\theta_y \cdot \sigma_Y(X)\big)^2\Big) ,\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta_y\)</span> is the adaptive rescaling weight for a certain <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>In contrast to the standard temperature scaling approach by <a class="footnote-reference brackets" href="#id7" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>, <a class="footnote-reference brackets" href="#id8" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>, the GP-Normal utilizes a Gaussian process
to obtain <span class="math notranslate nohighlight">\(\theta_y\)</span>, so that</p>
<div class="math notranslate nohighlight">
\[\theta_y \sim \text{gp}(0, k) ,\]</div>
<p>where <span class="math notranslate nohighlight">\(k\)</span> is the kernel function (for a more detailed description of the underlying Gaussian process, see
documentation of parent class <a class="reference internal" href="netcal.regression.gp.AbstractGP.html#netcal.regression.gp.AbstractGP" title="netcal.regression.gp.AbstractGP"><code class="xref py py-class docutils literal notranslate"><span class="pre">netcal.regression.gp.AbstractGP</span></code></a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_inducing_points</strong> (<em>int</em>) â Number of inducing points used to approximate the input space. These inducing points are also optimized.</p></li>
<li><p><strong>n_random_samples</strong> (<em>int</em>) â Number of random samples used to sample from the parameter distribution during optimization and inference.</p></li>
<li><p><strong>correlations</strong> (<em>bool</em><em>, </em><em>default: False</em><em>,</em>) â If True, perform covariance estimation recalibration if the input during fit/transform is given as multiple
independent distributions, e.g., by a mean and standard deviation vector for each sample.
If the input is given as a mean vector and a covariance matrix for each sample, this method applies
covariance recalibration by learning a recalibration weight for each entry.
If False, perform standard regression recalibration and output independent probability distributions.</p></li>
<li><p><strong>n_epochs</strong> (<em>int</em><em>, </em><em>default: 200</em>) â Number of optimization epochs.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default: 256</em>) â Size of batches during optimization.</p></li>
<li><p><strong>num_workers</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default: 0</em>) â Number of workers used for the dataloader.</p></li>
<li><p><strong>lr</strong> (<em>float</em><em>, </em><em>optional</em><em>, </em><em>default: 1e-2</em>) â Learning rate used for the Adam optimizer.</p></li>
<li><p><strong>use_cuda</strong> (<em>str</em><em> or </em><em>bool</em><em>, </em><em>optional</em><em>, </em><em>default: False</em>) â The optimization and inference might also run on a CUDA device. If True, use the first available CUDA device.
You can also pass a string âcuda:0â, âcuda:1â, etc. to specify the CUDA device.
If False, use CPU for optimization and inference.</p></li>
<li><p><strong>jitter</strong> (<em>float</em><em>, </em><em>optional</em><em>, </em><em>default: 1e-5</em>) â Small digit that is added to the diagonal of a covariance matrix to stabilize Cholesky decomposition during
Gaussian process optimization.</p></li>
<li><p><strong>name_prefix</strong> (<em>str</em><em>, </em><em>optional</em><em>, </em><em>default: &quot;gpnormal&quot;</em>) â Name prefix internally used in Pyro to distinguish between parameter stores.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id7" role="note">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id5">2</a>)</span>
<p>Levi, Dan, et al.:
âEvaluating and calibrating uncertainty prediction in regression tasks.â
arXiv preprint arXiv:1905.11659 (2019).
<a class="reference external" href="https://arxiv.org/pdf/1905.11659.pdf">Get source online</a></p>
</aside>
<aside class="footnote brackets" id="id8" role="note">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id2">1</a>,<a role="doc-backlink" href="#id6">2</a>)</span>
<p>Laves, Max-Heinrich, et al.:
âWell-calibrated regression uncertainty in medical imaging with deep learning.â
Medical Imaging with Deep Learning. PMLR, 2020.
<a class="reference external" href="http://proceedings.mlr.press/v121/laves20a/laves20a.pdf">Get source online</a></p>
</aside>
<aside class="footnote brackets" id="id9" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>KÃ¼ppers, Fabian, Schneider, Jonas, and Haselhoff, Anselm:
âParametric and Multivariate Uncertainty Calibration for Regression and Object Detection.â
European Conference on Computer Vision (ECCV) Workshops, 2022.
<a class="reference external" href="https://arxiv.org/pdf/2207.01242.pdf">Get source online</a></p>
</aside>
<aside class="footnote brackets" id="id10" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">4</a><span class="fn-bracket">]</span></span>
<p>Hao Song, Tom Diethe, Meelis Kull and Peter Flach:
âDistribution calibration for regression.â
International Conference on Machine Learning. PMLR, 2019.
<a class="reference external" href="http://proceedings.mlr.press/v97/song19a/song19a.pdf">Get source online</a></p>
</aside>
</aside>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code>([n_inducing_points,Â ...])</p></td>
<td><p>Constructor.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_module</span></code>(name,Â module)</p></td>
<td><p>Adds a child module to the current module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">added_loss_terms</span></code>()</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bfloat16</span></code>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">buffers</span></code>([recurse])</p></td>
<td><p>Returns an iterator over module buffers.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">children</span></code>()</p></td>
<td><p>Returns an iterator over immediate children modules.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">clear</span></code>()</p></td>
<td><p>Clear module parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">constraint_for_parameter_name</span></code>(param_name)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">constraints</span></code>()</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cpu</span></code>()</p></td>
<td><p>Moves all model parameters and buffers to the CPU.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cuda</span></code>([device])</p></td>
<td><p>Moves all model parameters and buffers to the GPU.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">double</span></code>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">double</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">epsilon</span></code>(dtype)</p></td>
<td><p>Get the smallest digit that is representable depending on the passed dtype (NumPy or PyTorch).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">eval</span></code>()</p></td>
<td><p>Sets the module in evaluation mode.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">extra_repr</span></code>()</p></td>
<td><p>Additional information used to print if str(method) is called.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code>(X,Â y[,Â tensorboard])</p></td>
<td><p>Fit a GP model to the provided data using Gaussian process optimization.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code>(X[,Â y])</p></td>
<td><p>Fit to data, then transform it.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">float</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code>(x)</p></td>
<td><p>Forward method defines the prior for the GP.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_buffer</span></code>(target)</p></td>
<td><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_extra_state</span></code>()</p></td>
<td><p>Returns any extra state to include in the module's state_dict.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_fantasy_model</span></code>(inputs,Â targets,Â **kwargs)</p></td>
<td><p>Returns a new GP model that incorporates the specified inputs and targets as new training data using online variational conditioning (OVC).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_parameter</span></code>(target)</p></td>
<td><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code>([deep])</p></td>
<td><p>Overwrite base method's get_params function to also capture child parameters as variational strategy, LMC coefficients, etc.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_submodule</span></code>(target)</p></td>
<td><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">guide</span></code>(x,Â y)</p></td>
<td><p>Pyro guide that defines the variational distribution for the Gaussian process.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">half</span></code>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">half</span></code> datatype.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">hyperparameters</span></code>()</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code>(**kwargs)</p></td>
<td><p>Set a value for a parameter</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">ipu</span></code>([device])</p></td>
<td><p>Moves all model parameters and buffers to the IPU.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_model</span></code>(filename[,Â use_cuda])</p></td>
<td><p>Overwrite base method's load_model function as the parameters for the GP methods are stored differently compared to the remaining methods.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_state_dict</span></code>(state_dict[,Â strict])</p></td>
<td><p>Copies parameters and buffers from <code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code> into this module and its descendants.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_strict_shapes</span></code>(value)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">local_load_samples</span></code>(samples_dict,Â memo,Â prefix)</p></td>
<td><p>Defines local behavior of this Module when loading parameters from a samples_dict generated by a Pyro sampling mechanism.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">model</span></code>(x,Â y)</p></td>
<td><p>Model function that defines the computation graph.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">modules</span></code>()</p></td>
<td><p>Returns an iterator over all modules in the network.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_added_loss_terms</span></code>()</p></td>
<td><p>Returns an iterator over module variational strategies, yielding both the name of the variational strategy as well as the strategy itself.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_buffers</span></code>([prefix,Â recurse])</p></td>
<td><p>Returns an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_children</span></code>()</p></td>
<td><p>Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_constraints</span></code>([memo,Â prefix])</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_hyperparameters</span></code>()</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_modules</span></code>([memo,Â prefix,Â remove_duplicate])</p></td>
<td><p>Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_parameters</span></code>([prefix,Â recurse])</p></td>
<td><p>Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_parameters_and_constraints</span></code>()</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_priors</span></code>([memo,Â prefix])</p></td>
<td><p>Returns an iterator over the module's priors, yielding the name of the prior, the prior, the associated parameter names, and the transformation callable.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_variational_parameters</span></code>()</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code>([recurse])</p></td>
<td><p>Returns an iterator over module parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">pyro_guide</span></code>(input[,Â beta,Â name_prefix])</p></td>
<td><p>(For Pyro integration only).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">pyro_load_from_samples</span></code>(samples_dict)</p></td>
<td><p>Convert this Module in to a batch Module by loading parameters from the given <cite>samples_dict</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">pyro_model</span></code>(input[,Â beta,Â name_prefix])</p></td>
<td><p>(For Pyro integration only).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">pyro_sample_from_prior</span></code>()</p></td>
<td><p>For each parameter in this Module and submodule that have defined priors, sample a value for that parameter from its corresponding prior with a pyro.sample primitive and load the resulting value in to the parameter.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_added_loss_term</span></code>(name)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_backward_hook</span></code>(hook)</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_buffer</span></code>(name,Â tensor[,Â persistent])</p></td>
<td><p>Adds a buffer to the module.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_constraint</span></code>(param_name,Â constraint)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code>(hook)</p></td>
<td><p>Registers a forward hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code>(hook)</p></td>
<td><p>Registers a forward pre-hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_hook</span></code>(hook)</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_load_state_dict_post_hook</span></code>(hook)</p></td>
<td><p>Registers a post hook to be run after module's <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> is called.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_module</span></code>(name,Â module)</p></td>
<td><p>Alias for <code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_parameter</span></code>(name,Â parameter)</p></td>
<td><p>Adds a parameter to the module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_prior</span></code>(name,Â prior,Â param_or_closure)</p></td>
<td><p>Adds a prior to the module.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">requires_grad_</span></code>([requires_grad])</p></td>
<td><p>Change if autograd should record operations on parameters in this module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample_from_prior</span></code>(prior_name)</p></td>
<td><p>Sample parameter values from prior.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_model</span></code>(filename)</p></td>
<td><p>Save model instance as with torch's save function as this is safer for torch tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_extra_state</span></code>(state)</p></td>
<td><p>This function is called from <code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code> to handle any extra state found within the <cite>state_dict</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_memory</span></code>()</p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_dict</span></code>(*args[,Â destination,Â prefix,Â ...])</p></td>
<td><p>Returns a dictionary containing a whole state of the module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code>(*args,Â **kwargs)</p></td>
<td><p>Moves and/or casts the parameters and buffers.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_empty</span></code>(*,Â device)</p></td>
<td><p>Moves the parameters and buffers to the specified device without copying storage.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_pyro_random_module</span></code>()</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code>([mode])</p></td>
<td><p>Sets the module in training mode.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code>(X)</p></td>
<td><p>Transform the given stddev to a distribution-calibrated one using the input mean and stddev as priors for the underlying Gaussian process.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">type</span></code>(dst_type)</p></td>
<td><p>Casts all parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dst_type</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">update_added_loss_term</span></code>(name,Â added_loss_term)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">variational_parameters</span></code>()</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">xpu</span></code>([device])</p></td>
<td><p>Moves all model parameters and buffers to the XPU.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code>([set_to_none])</p></td>
<td><p>Sets gradients of all model parameters to zero.</p></td>
</tr>
</tbody>
</table>
</dd></dl>

</section>


                </div>
              </div>
            </div>
          </div>
        </div>
        
        
      </div><!-- /row -->

      <!-- row -->
      <div class="row footer-relbar">
<div id="navbar-related" class=" related navbar navbar-default" role="navigation" aria-label="related navigation">
  <div class="navbar-inner">
    <ul class="nav navbar-nav ">
        <li><a href="../../../index.html">net:cal API Reference</a></li>
    </ul>
<ul class="nav navbar-nav pull-right hidden-xs hidden-sm">
      
        <li><a href="netcal.regression.gp.GPBeta.html" title="netcal.regression.gp.GPBeta" >previous</a></li>
        <li><a href="netcal.regression.gp.GPCauchy.html" title="netcal.regression.gp.GPCauchy" >next</a></li>
        <li><a href="../../../py-modindex.html" title="Python Module Index" >modules</a></li>
        <li><a href="../../../genindex.html" title="General Index" >index</a></li>
        <li><a href="../../netcal.regression.html" >netcal.regression</a></li>
        <li><a href="../netcal.regression.gp.html" >netcal.regression.gp</a></li>
        <li><a href="#">top</a></li> 
      
    </ul>
  </div>
</div>
      </div><!-- /row -->

      <!-- footer -->
      <footer role="contentinfo">
      </footer>
      <!-- /footer -->

    </div>
    <!-- /container -->

  </body>
</html>