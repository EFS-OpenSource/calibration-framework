<!DOCTYPE html>




<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>netcal.scaling.BetaCalibrationDependent &mdash; net:cal API Reference</title>
    <meta name="description" content="">
    <meta name="author" content="">

    

<link rel="stylesheet" href="../../_static/css/basicstrap-base.css" type="text/css" />
<link rel="stylesheet" id="current-theme" href="../../_static/css/bootstrap3/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" id="current-adjust-theme" type="text/css" />

<link rel="stylesheet" href="../../_static/css/font-awesome.min.css">

<style type="text/css">
  body {
    padding-top: 60px;
    padding-bottom: 40px;
  }
</style>

<link rel="stylesheet" href="../../_static/css/basicstrap.css" type="text/css" />
<link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
<link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
<link rel="stylesheet" href="../../_static/css/basicstrap.css" type="text/css" />
    
<script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
            URL_ROOT:    '../../',
            VERSION:     '1.3.1',
            COLLAPSE_INDEX: false,
            FILE_SUFFIX: '.html',
            HAS_SOURCE:  true
  };
</script>
    <script type="text/javascript" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/js/jquery.min.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/sphinx_highlight.js"></script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/javascript" src="../../_static/js/bootstrap3.min.js"></script>
<script type="text/javascript" src="../../_static/js/jquery.cookie.min.js"></script>
<script type="text/javascript" src="../../_static/js/basicstrap.js"></script>
<script type="text/javascript">
</script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="top" title="net:cal API Reference" href="../../index.html" />
    <link rel="up" title="netcal.scaling" href="../netcal.scaling.html" />
    <link rel="next" title="netcal.regularization" href="../netcal.regularization.html" />
    <link rel="prev" title="netcal.scaling.BetaCalibration" href="netcal.scaling.BetaCalibration.html" /> 
  </head>
  <body role="document">
    <div id="navbar-top" class="navbar navbar-fixed-top navbar-default" role="navigation" aria-label="top navigation">
      <div class="container-fluid">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../../index.html">net:cal API Reference</a>
        </div>
        <div class="navbar-collapse collapse">
          <ul class="nav navbar-nav navbar-right">
              <li class="dropdown visible-xs">
                <a role="button" id="localToc" data-toggle="dropdown" data-target="#" href="#">Table Of Contents <b class="caret"></b></a>
                <ul class="dropdown-menu localtoc sp-localtoc" role="menu" aria-labelledby="localToc">
                <ul>
<li><a class="reference internal" href="#">netcal.scaling.BetaCalibrationDependent</a><ul>
<li><a class="reference internal" href="#netcal.scaling.BetaCalibrationDependent"><code class="docutils literal notranslate"><span class="pre">BetaCalibrationDependent</span></code></a></li>
</ul>
</li>
</ul>

                </ul>
              </li>

            
              <li><a href="netcal.scaling.BetaCalibration.html" title="netcal.scaling.BetaCalibration" accesskey="P">previous </a></li>
              <li><a href="../netcal.regularization.html" title="netcal.regularization" accesskey="N">next </a></li>
              <li><a href="../../py-modindex.html" title="Python Module Index" >modules </a></li>
              <li><a href="../../genindex.html" title="General Index" accesskey="I">index </a></li>
              <li><a href="../netcal.scaling.html" accesskey="U">netcal.scaling</a></li>
            
            <li class="visible-xs"><a href="../../_sources/_autosummary/_autosummary_scaling/netcal.scaling.BetaCalibrationDependent.rst.txt" rel="nofollow">Show Source</a></li>

            <li class="visible-xs">
                <form class="search form-search form-inline navbar-form navbar-right sp-searchbox" action="../../search.html" method="get">
                  <div class="input-append input-group">
                    <input type="text" class="search-query form-control" name="q" placeholder="Search...">
                    <span class="input-group-btn">
                    <input type="submit" class="btn" value="Go" />
                    </span>
                  </div>
                  <input type="hidden" name="check_keywords" value="yes" />
                  <input type="hidden" name="area" value="default" />
                </form>
            </li>

            

          </ul>

        </div>
      </div>
    </div>
    

    <!-- container -->
    <div class="container-fluid">

      <!-- row -->
      <div class="row">
         
<div class="col-md-3 hidden-xs" id="sidebar-wrapper">
  <div class="sidebar hidden-xs" role="navigation" aria-label="main navigation">
    <p class="logo"><a href="../../index.html">
      <img class="logo" src="../../_static/logo200x200.png" alt="Logo"/>
    </a></p>
<h3><a href="../../index.html">Table of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../netcal.binning.html">netcal.binning</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../netcal.scaling.html">netcal.scaling</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../netcal.scaling.html#scaling-methods-for-confidence-calibration">Scaling Methods for Confidence Calibration</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../netcal.scaling.html#available-classes">Available classes</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="netcal.scaling.AbstractLogisticRegression.html">netcal.scaling.AbstractLogisticRegression</a></li>
<li class="toctree-l3"><a class="reference internal" href="netcal.scaling.LogisticCalibration.html">netcal.scaling.LogisticCalibration</a></li>
<li class="toctree-l3"><a class="reference internal" href="netcal.scaling.LogisticCalibrationDependent.html">netcal.scaling.LogisticCalibrationDependent</a></li>
<li class="toctree-l3"><a class="reference internal" href="netcal.scaling.TemperatureScaling.html">netcal.scaling.TemperatureScaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="netcal.scaling.BetaCalibration.html">netcal.scaling.BetaCalibration</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">netcal.scaling.BetaCalibrationDependent</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#netcal.scaling.BetaCalibrationDependent"><code class="docutils literal notranslate"><span class="pre">BetaCalibrationDependent</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../netcal.regularization.html">netcal.regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../netcal.metrics.html">netcal.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../netcal.presentation.html">netcal.presentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../netcal.regression.html">netcal.regression</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../_autosummary_abstract_calibration/netcal.AbstractCalibration.html">netcal.AbstractCalibration</a></li>
</ul>

<div id="searchbox" role="search">
  <h3>Quick search</h3>
  <form class="search form-inline" action="../../search.html" method="get">
      <div class="input-append input-group">
        <input type="text" class="search-query form-control" name="q" placeholder="Search...">
        <span class="input-group-btn">
        <input type="submit" class="btn" value="Go" />
        </span>
      </div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
  </div>
</div> 
        

        <div class="col-md-9" id="content-wrapper">
          <div class="document" role="main">
            <div class="documentwrapper">
              <div class="bodywrapper">
                <div class="body">
                  
  <section id="netcal-scaling-betacalibrationdependent">
<h1>netcal.scaling.BetaCalibrationDependent<a class="headerlink" href="#netcal-scaling-betacalibrationdependent" title="Permalink to this heading">Â¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="netcal.scaling.BetaCalibrationDependent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">netcal.scaling.</span></span><span class="sig-name descname"><span class="pre">BetaCalibrationDependent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'momentum'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#netcal.scaling.BetaCalibrationDependent" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This calibration method uses a multivariate variant of a Beta distribution to obtain a
calibration mapping by means of the confidence as well as additional features. This method is originally
proposed by <a class="footnote-reference brackets" href="#id5" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>. This calibration scheme
tries to model several dependencies in the variables given by the input <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p>
<p>It is necessary to provide all data in input parameter <code class="docutils literal notranslate"><span class="pre">X</span></code> as an NumPy array of shape <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_features)</span></code>,
whereas the confidence must be the first feature given in the input array. The ground-truth samples <code class="docutils literal notranslate"><span class="pre">y</span></code>
must be an array of shape <code class="docutils literal notranslate"><span class="pre">(n_samples,)</span></code> consisting of binary labels <span class="math notranslate nohighlight">\(y \in \{0, 1\}\)</span>. Those
labels indicate if the according sample has matched a ground truth box <span class="math notranslate nohighlight">\(\text{m}=1\)</span> or is a false
prediction <span class="math notranslate nohighlight">\(\text{m}=0\)</span>.</p>
<p><strong>Mathematical background:</strong> For confidence calibration in classification tasks, a
confidence mapping <span class="math notranslate nohighlight">\(g\)</span> is applied on top of a miscalibrated scoring classifier <span class="math notranslate nohighlight">\(\hat{p} = h(x)\)</span> to
deliver a calibrated confidence score <span class="math notranslate nohighlight">\(\hat{q} = g(h(x))\)</span>.</p>
<p>For detection calibration, we can also use the additional box regression output which we denote as
<span class="math notranslate nohighlight">\(\hat{r} \in [0, 1]^J\)</span> with <span class="math notranslate nohighlight">\(J\)</span> as the number of dimensions used for the box encoding (e.g.
<span class="math notranslate nohighlight">\(J=4\)</span> for x position, y position, width and height).
Therefore, the calibration map is not only a function of the confidence score, but also of <span class="math notranslate nohighlight">\(\hat{r}\)</span>.
To define a general calibration map for binary problems, we use the logistic function and the combined
input <span class="math notranslate nohighlight">\(s = (\hat{p}, \hat{r})\)</span> of size K by</p>
<div class="math notranslate nohighlight">
\[g(s) = \frac{1}{1 + \exp(-z(s))} ,\]</div>
<p>According to <a class="footnote-reference brackets" href="#id5" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>, we can interpret the logit <span class="math notranslate nohighlight">\(z\)</span> as the logarithm of the posterior odds</p>
<div class="math notranslate nohighlight">
\[z(s) = \log \frac{f(\text{m}=1 | s)}{f(\text{m}=0 | s)} \approx
\log \frac{f(s | \text{m}=1)}{f(s | \text{m}=1)} = \ell r(s)\]</div>
<p>For a multivariate probability density function <span class="math notranslate nohighlight">\(f(s|\text{m})\)</span>, we use a variant of the beta distribution
described in <a class="footnote-reference brackets" href="#id6" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a> and given by</p>
<div class="math notranslate nohighlight">
\[f(s|\text{m}) =  \frac{1}{B(\alpha_0, ..., \alpha_K)}
                  \frac{\prod^K_{k=1} \lambda_k^{\alpha_k}(s_k^\ast)^{\alpha_k - 1}
                  \Big(\frac{s_k^\ast}{s_k}\Big)^2}
                  {\Big[1 + \sum^K_{k=1} \lambda_k
                    s_k^\ast\Big]^{\sum^K_{k=0} \alpha_k}
                  }\]</div>
<p>with shape parameters <span class="math notranslate nohighlight">\(\alpha_k, \beta_k &gt; 0\)</span>, <span class="math notranslate nohighlight">\(\forall k \in \{0, ..., K \}\)</span>. For notation
easyness, we denote <span class="math notranslate nohighlight">\(\lambda_k=\frac{\beta_k}{\beta_0}\)</span> and <span class="math notranslate nohighlight">\(s^\ast=\frac{s}{1-s}\)</span>.
Inserting this density function into this framework with <span class="math notranslate nohighlight">\(\alpha_k^+\)</span>, <span class="math notranslate nohighlight">\(\beta_k^+\)</span> and
<span class="math notranslate nohighlight">\(\alpha_k^-\)</span>, <span class="math notranslate nohighlight">\(\beta_k^-\)</span> as the distribution parameters for <span class="math notranslate nohighlight">\(\text{m}=1\)</span> and
<span class="math notranslate nohighlight">\(\text{m}=0\)</span>, respectively, we get a likelihood ratio of</p>
<div class="math notranslate nohighlight">
\[\begin{split}\ell r(s) &amp;= \sum^K_{k=1} \alpha_k^+ \log(\lambda_k^+) - \alpha_k^- \log(\lambda_k^-) \\
           &amp;+ \sum^K_{k=1} (\alpha_k^+ - \alpha_k^-) \log(s^\ast) \\
           &amp;+ \sum^K_{k=0} \alpha_k^- \log\Bigg[\sum^K_{j=1} \lambda_j^- s^\ast_j\Bigg] \\
           &amp;- \sum^K_{k=0} \alpha_k^+ \log\Bigg[\sum^K_{j=1} \lambda_j^+ s^\ast_j\Bigg] \\
           &amp;+ c ,\end{split}\]</div>
<p>where  and
<span class="math notranslate nohighlight">\(c=\log B(\alpha_0^-, ..., \alpha_k^-) - \log B(\alpha_0^+, ..., \alpha^+_k)\)</span>.</p>
<p>This is optimized by an Adam optimizer with a learning rate of 1e-3 and a batch size of 256 for
1000 iterations (default).</p>
<p>Capturing epistemic uncertainty of the calibration method is also able with this implementation <a class="footnote-reference brackets" href="#id7" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> (<em>str</em><em>, </em><em>default: &quot;momentum&quot;</em>) â Method that is used to obtain a calibration mapping:
- âmleâ: Maximum likelihood estimate without uncertainty using a convex optimizer.
- âmomentumâ: MLE estimate using Momentum optimizer for non-convex optimization.
- âvariationalâ: Variational Inference with uncertainty.
- âmcmcâ: Markov-Chain Monte-Carlo sampling with uncertainty.</p></li>
<li><p><strong>momentum_epochs</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default: 1000</em>) â Number of epochs used by momentum optimizer.</p></li>
<li><p><strong>mcmc_steps</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default: 20</em>) â Number of weight samples obtained by MCMC sampling.</p></li>
<li><p><strong>mcmc_chains</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default: 1</em>) â Number of Markov-chains used in parallel for MCMC sampling (this will result
in mcmc_steps * mcmc_chains samples).</p></li>
<li><p><strong>mcmc_warmup_steps</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default: 100</em>) â Warmup steps used for MCMC sampling.</p></li>
<li><p><strong>vi_epochs</strong> (<em>int</em><em>, </em><em>optional</em><em>, </em><em>default: 1000</em>) â Number of epochs used for ELBO optimization.</p></li>
<li><p><strong>independent_probabilities</strong> (<em>bool</em><em>, </em><em>optional</em><em>, </em><em>default: False</em>) â Boolean for multi class probabilities.
If set to True, the probability estimates for each
class are treated as independent of each other (sigmoid).</p></li>
<li><p><strong>use_cuda</strong> (<em>str</em><em> or </em><em>bool</em><em>, </em><em>optional</em><em>, </em><em>default: False</em>) â Specify if CUDA should be used. If str, you can also specify the device
number like âcuda:0â, etc.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id5" role="note">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id2">2</a>)</span>
<p>Fabian KÃ¼ppers, Jan Kronenberger, Amirhossein Shantia and Anselm Haselhoff:
âMultivariate Confidence Calibration for Object Detection.â
The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2020.</p>
</aside>
<aside class="footnote brackets" id="id6" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">2</a><span class="fn-bracket">]</span></span>
<p>Libby, David L., and Melvin R. Novick:
âMultivariate generalized beta distributions with applications to utility assessmentâ
Journal of Educational Statistics 7.4, pp. 271-294, 1982</p>
</aside>
<aside class="footnote brackets" id="id7" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">3</a><span class="fn-bracket">]</span></span>
<p>Fabian KÃ¼ppers, Jan Kronenberger, Jonas Schneider  and Anselm Haselhoff:
âBayesian Confidence Calibration for Epistemic Uncertainty Modelling.â
2021 IEEE Intelligent Vehicles Symposium (IV), 2021</p>
</aside>
</aside>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code>(*args[,Â method])</p></td>
<td><p>Create an instance of <cite>BetaCalibrationDependent</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">clear</span></code>()</p></td>
<td><p>Clear model parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">convex</span></code>(data,Â y,Â tensorboard,Â log_dir)</p></td>
<td><p>Convex optimization to find the global optimum of current parameter search.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code>(X,Â y[,Â random_state,Â tensorboard,Â log_dir])</p></td>
<td><p>Build logitic calibration model either conventional with single MLE estimate or with Variational Inference (VI) or Markov-Chain Monte-Carlo (MCMC) algorithm to also obtain uncertainty estimates.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code>(X[,Â y])</p></td>
<td><p>Fit to data, then transform it.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">guide</span></code>([X,Â y])</p></td>
<td><p>Variational substitution definition for each parameter.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_model</span></code>(filename)</p></td>
<td><p>Load model from saved torch dump.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">mask</span></code>()</p></td>
<td><p>Seek for all relevant weights whose values are negative.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">mcmc</span></code>(data,Â y,Â tensorboard,Â log_dir)</p></td>
<td><p>Perform Markov-Chain Monte-Carlo sampling on the (unknown) posterior.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">model</span></code>([X,Â y])</p></td>
<td><p>Definition of the log regression model.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">momentum</span></code>(data,Â y,Â tensorboard,Â log_dir)</p></td>
<td><p>Momentum optimization to find the global optimum of current parameter search.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">prepare</span></code>(X)</p></td>
<td><p>Preprocessing of input data before called at the beginning of the fit-function.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">prior</span></code>(dtype)</p></td>
<td><p>Prior definition of the weights used for log regression.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_model</span></code>(filename)</p></td>
<td><p>Save model instance as with torch's save function as this is safer for torch tensors.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code>(device)</p></td>
<td><p>Set distribution parameters to the desired device in order to compute either on CPU or GPU.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code>(X[,Â num_samples,Â random_state,Â ...])</p></td>
<td><p>After model calibration, this function is used to get calibrated outputs of uncalibrated confidence estimates.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">variational</span></code>(data,Â y,Â tensorboard,Â log_dir)</p></td>
<td><p>Perform variational inference using the guide.</p></td>
</tr>
</tbody>
</table>
</dd></dl>

</section>


                </div>
              </div>
            </div>
          </div>
        </div>
        
        
      </div><!-- /row -->

      <!-- row -->
      <div class="row footer-relbar">
<div id="navbar-related" class=" related navbar navbar-default" role="navigation" aria-label="related navigation">
  <div class="navbar-inner">
    <ul class="nav navbar-nav ">
        <li><a href="../../index.html">net:cal API Reference</a></li>
    </ul>
<ul class="nav navbar-nav pull-right hidden-xs hidden-sm">
      
        <li><a href="netcal.scaling.BetaCalibration.html" title="netcal.scaling.BetaCalibration" >previous</a></li>
        <li><a href="../netcal.regularization.html" title="netcal.regularization" >next</a></li>
        <li><a href="../../py-modindex.html" title="Python Module Index" >modules</a></li>
        <li><a href="../../genindex.html" title="General Index" >index</a></li>
        <li><a href="../netcal.scaling.html" >netcal.scaling</a></li>
        <li><a href="#">top</a></li> 
      
    </ul>
  </div>
</div>
      </div><!-- /row -->

      <!-- footer -->
      <footer role="contentinfo">
      </footer>
      <!-- /footer -->

    </div>
    <!-- /container -->

  </body>
</html>